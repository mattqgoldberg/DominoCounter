{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domino Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import re\n",
    "import torch\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up domino dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dominoMap = {\n",
    "    (0,0): 0,\n",
    "    (0,1): 1,\n",
    "    (0,2): 2,\n",
    "    (1,1): 3,\n",
    "    (1,2): 4,\n",
    "    (2,2): 5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.GaussianBlur(kernel_size=3),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_file_path = self.image_paths[idx]\n",
    "        image = cv2.imread(image_file_path, cv2.IMREAD_GRAYSCALE)\n",
    "        image = Image.fromarray(image)\n",
    "        image = self.transform(image)\n",
    "\n",
    "        match = re.search(r'(\\d+)-(\\d+)', image_file_path)\n",
    "        if not match:\n",
    "            raise ValueError(f'Invalid image file path: {image_file_path}')\n",
    "        num1, num2 = map(int, match.groups())\n",
    "\n",
    "        # Get label\n",
    "        label = dominoMap[(num1, num2)]\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "if not os.path.exists('./data'):\n",
    "    response = requests.get('https://www.kaggle.com/api/v1/datasets/download/mattqgoldberg/double-2-dominoes')\n",
    "\n",
    "    with open('./double-2-dominoes.zip', 'wb') as f:\n",
    "        f.write(response.content)\n",
    "\n",
    "\n",
    "\n",
    "    with zipfile.ZipFile('./double-2-dominoes.zip', 'r') as zip_ref:\n",
    "        zip_ref.extractall('./data')\n",
    "\n",
    "else:\n",
    "    print('Data already exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from multiple directories\n",
    "\n",
    "dataset_paths = ['./data/images']\n",
    "\n",
    "image_paths = []\n",
    "for path in dataset_paths:\n",
    "    for subdir in os.listdir(path):\n",
    "        if os.path.isdir(os.path.join(path, subdir)):\n",
    "            for img in os.listdir(os.path.join(path, subdir)):\n",
    "                image_paths.append(os.path.join(path, subdir, img))\n",
    "            \n",
    "\n",
    "# Split into training and testing sets\n",
    "train_images, test_images = train_test_split(image_paths, test_size=0.2)\n",
    "\n",
    "# Create train and test datasets\n",
    "train_dataset = CustomDataset(train_images, \"\")\n",
    "test_dataset = CustomDataset(test_images, \"\")\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "print(f\"Num images in train set: {len(train_loader.dataset)}\")\n",
    "print(f\"Num images in test set: {len(test_loader.dataset)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize a sample image and transform it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random image from the training dataset\n",
    "random_idx = random.randint(0, len(train_dataset) - 1)\n",
    "image_path = train_dataset.image_paths[random_idx]\n",
    "\n",
    "# Load the original image\n",
    "original_image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "image = original_image.copy()\n",
    "image = Image.fromarray(image)\n",
    "\n",
    "# Apply transformations\n",
    "transform_pipeline = transforms.Compose([\n",
    "            transforms.Grayscale(num_output_channels=1),\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.GaussianBlur(kernel_size=3),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.3, contrast=0.3),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "        ])\n",
    "\n",
    "transformed_image = transform_pipeline(image)\n",
    "\n",
    "# Convert tensors back to images for visualization\n",
    "def tensor_to_image(tensor):\n",
    "    tensor = tensor.squeeze(0)  # Remove channel dimension\n",
    "    tensor = tensor * 0.5 + 0.5  # Undo normalization\n",
    "    return tensor.numpy()\n",
    "\n",
    "# Plot original and transformed images\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# Show original image\n",
    "axes[0].imshow(original_image, cmap=\"gray\")\n",
    "axes[0].set_title(\"Original Image\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "# Show transformed image\n",
    "axes[1].imshow(tensor_to_image(transformed_image.T), cmap=\"gray\")\n",
    "axes[1].set_title(\"Transformed Image\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "# Display the images\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CNN Model Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipCNN(nn.Module):\n",
    "    def __init__(self, num_classes=3):\n",
    "        super(PipCNN, self).__init__()\n",
    "        \n",
    "        # First Convolutional Block\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv1_2 = nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1_2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.conv2_2 = nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2_2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv3_2 = nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3_2 = nn.BatchNorm2d(128)\n",
    "\n",
    "        # Fourth Convolutional Block\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "\n",
    "        # Pooling Layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        # Global Average Pooling (GAP)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(256, 128)\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # First Block\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn1_2(self.conv1_2(x))))\n",
    "\n",
    "        # Second Block\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn2_2(self.conv2_2(x))))\n",
    "\n",
    "        # Third Block\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.pool(F.relu(self.bn3_2(self.conv3_2(x))))\n",
    "\n",
    "        # Fourth Block\n",
    "        x = self.pool(F.relu(self.bn4(self.conv4(x))))\n",
    "\n",
    "        # Global Average Pooling (GAP)\n",
    "        x = self.global_avg_pool(x)\n",
    "        x = torch.flatten(x, 1)  # Flatten along the channel dimension\n",
    "\n",
    "        # Fully Connected Layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "epochs = 10\n",
    "lr = 0.001\n",
    "weight_decay = 1e-3\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = PipCNN(num_classes=6).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
    "\n",
    "\n",
    "loss_list = []\n",
    "acc_list = []\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    avg_loss = 0\n",
    "    avg_acc = 0\n",
    "\n",
    "    # Iterate over the training dataset\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        correct_predictions += (predictions == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "    \n",
    "    # Calculate average loss and accuracy\n",
    "    train_accuracy = correct_predictions / total_samples\n",
    "    acc_list.append(train_accuracy)\n",
    "    loss_list.append(total_loss/len(train_loader))\n",
    "    \n",
    "    scheduler.step()    \n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_loader):.4f}, Train Accuracy: {train_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_loss_and_accuracy(loss_list, acc_list):\n",
    "    plt.plot(loss_list, label='Loss')\n",
    "    plt.plot(acc_list, label='Training Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.title('Loss and Training Acc per Epoch')\n",
    "    plt.axhline(y=1, color='r', linestyle=':')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "graph_loss_and_accuracy(loss_list, acc_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate against the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run evaluation on the test set\n",
    "model.eval()\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        predictions = torch.argmax(outputs, dim=1)\n",
    "        test_correct += (predictions == labels).sum().item()\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "test_accuracy = test_correct / test_total\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}, Test Correct: {test_correct}, Test Total: {test_total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show some sample predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize test predictions\n",
    "def visualize_predictions(model, test_loader, class_names, num_images=32):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "    \n",
    "    images, labels = next(iter(test_loader))  # Get a batch of test images\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "    \n",
    "    images = images.cpu().numpy()\n",
    "    \n",
    "    # Denormalize images for visualization\n",
    "    images = images * 0.5 + 0.5\n",
    "\n",
    "    fig, axes = plt.subplots(4, 4, figsize=(30, 40))  # Create a 4x4 grid\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx in range(num_images):\n",
    "        img = images[idx].squeeze(0)  # Remove extra channel dimension\n",
    "        axes[idx].imshow(img, cmap=\"gray\")\n",
    "        axes[idx].axis(\"off\")\n",
    "        \n",
    "        # Get true and predicted labels\n",
    "        true_label = class_names[labels[idx].item()]\n",
    "        predicted_label = class_names[preds[idx].item()]\n",
    "        \n",
    "        # Set title with color coding\n",
    "        color = \"green\" if true_label == predicted_label else \"red\"\n",
    "        axes[idx].set_title(f\"Pred: {predicted_label}\\nTrue: {true_label}\", color=color, fontsize=40)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Define class names\n",
    "class_names = [\"0-0\", \"0-1\", \"0-2\", \"1-1\", \"1-2\", \"2-2\"]\n",
    "\n",
    "# visualize test predictions\n",
    "test_loader_visual = DataLoader(test_dataset, batch_size=16, shuffle=True)\n",
    "visualize_predictions(model, test_loader_visual, class_names, num_images=16)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DominoCounter-xJe08csb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
